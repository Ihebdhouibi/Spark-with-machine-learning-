{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Clustering mall customers into Gold - Silver - Bronze customers depending on their spending score ').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('/Users/ihebd/PycharmProjects/Spark-with-machine-learning-/datasets/Mall_Customers.csv',\n",
    "                    header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Annual Income (k$): integer (nullable = true)\n",
      " |-- Spending Score (1-100): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, CustomerID: string, Gender: string, Age: string, Annual Income (k$): string, Spending Score (1-100): string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CustomerID=1, Gender='Male', Age=19, Annual Income (k$)=15, Spending Score (1-100)=39),\n",
       " Row(CustomerID=2, Gender='Male', Age=21, Annual Income (k$)=15, Spending Score (1-100)=81),\n",
       " Row(CustomerID=3, Gender='Female', Age=20, Annual Income (k$)=16, Spending Score (1-100)=6),\n",
       " Row(CustomerID=4, Gender='Female', Age=23, Annual Income (k$)=16, Spending Score (1-100)=77),\n",
       " Row(CustomerID=5, Gender='Female', Age=31, Annual Income (k$)=17, Spending Score (1-100)=40)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null/missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+------------------+----------------------+\n",
      "|CustomerID|Gender|Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "|         0|     0|  0|                 0|                     0|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+------------------+----------------------+\n",
      "|CustomerID|Gender|Age|Annual Income (k$)|Spending Score (1-100)|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "|         0|     0|  0|                 0|                     0|\n",
      "+----------+------+---+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create features vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset contains only one feature which is spending score as we aim to cluster customers depending on their speding score \n",
    "# Import VectorAssembler to create our features vector \n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "features = ['Spending Score (1-100)']\n",
    "\n",
    "feature_vector = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "ds = feature_vector.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CustomerID',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Annual Income (k$)',\n",
       " 'Spending Score (1-100)',\n",
       " 'features']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our clustering kmeans model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kmeans model\n",
    "kmeans = KMeans(featuresCol='features', k=3)\n",
    "\n",
    "# fit kmeans model \n",
    "model = kmeans.fit(ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.ml.clustering.KMeansSummary object at 0x000001D64BB8BD90>\n"
     ]
    }
   ],
   "source": [
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions  \n",
    "\n",
    "predictions = model.transform(ds)\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.8172327476215493\n"
     ]
    }
   ],
   "source": [
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|   94|\n",
      "|         2|   47|\n",
      "|         0|   59|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(ds).groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to cluster our customers into three groups depending on their spending score \n",
    "\n",
    "                * Cluster 1 : 47 customers\n",
    "                * Cluster 2 : 59 customers\n",
    "                * Cluster 3 : 94 customers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse and visualize our clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+\n",
      "|prediction|max(Annual Income (k$))|\n",
      "+----------+-----------------------+\n",
      "|         1|                     99|\n",
      "|         2|                    137|\n",
      "|         0|                    137|\n",
      "+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(ds).groupBy('prediction').max('Annual Income (k$)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+\n",
      "|prediction|min(Annual Income (k$))|\n",
      "+----------+-----------------------+\n",
      "|         1|                     15|\n",
      "|         2|                     16|\n",
      "|         0|                     15|\n",
      "+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(ds).groupBy('prediction').min('Annual Income (k$)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+\n",
      "|prediction|sum(Annual Income (k$))|\n",
      "+----------+-----------------------+\n",
      "|         1|                   5128|\n",
      "|         2|                   3158|\n",
      "|         0|                   3826|\n",
      "+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(ds).groupBy('prediction').sum('Annual Income (k$)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|         avg(Age)|\n",
      "+----------+-----------------+\n",
      "|         1|42.41489361702128|\n",
      "|         2|42.95744680851064|\n",
      "|         0|29.89830508474576|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(ds).groupBy('prediction').mean('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------+\n",
      "|prediction|sum(Spending Score (1-100))|\n",
      "+----------+---------------------------+\n",
      "|         1|                       4529|\n",
      "|         2|                        686|\n",
      "|         0|                       4825|\n",
      "+----------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(ds).groupBy('prediction').sum('Spending Score (1-100)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------+\n",
      "|prediction|avg(Spending Score (1-100))|\n",
      "+----------+---------------------------+\n",
      "|         1|         48.180851063829785|\n",
      "|         2|         14.595744680851064|\n",
      "|         0|          81.77966101694915|\n",
      "+----------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(ds).groupBy('prediction').avg('Spending Score (1-100)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
